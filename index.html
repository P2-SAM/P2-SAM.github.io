<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>P&sup2;SAM</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }


    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>
  <style>
    .center {
        display: block;
        margin-left: auto;
        margin-right: auto;
    }
    .gradient-text {
            background: linear-gradient(to right, #00f, #8a2be2, #f00); /* 渐变色定义 */
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
    }
  </style>
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="shortcut icon" href="./static/images/aim.ico" type="image/x-icon">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>



<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-3 publication-title"><span class="gradient-text">P&sup2;SAM: Probabilistically Prompted SAMs </span> Are <br> Efficient
            Segmentator for Ambiguous Medical Images</h1>
          <div class="is-size-5 publication-authors">

            <span class="author-block">
              <a href="https://openreview.net/profile?id=~Yuzhihuang1">Yuzhi Huang</a><sup>1†</sup>,</span>
            </span>

            <span class="author-block">
              <a href="https://xggnet.github.io/">Chenxin Li</a><sup>2†‡</sup>,</span>
            </span>

            <span class="author-block">
              <a href="https://openreview.net/profile?id=~ZiXu_Lin1">Zixu Lin</a><sup>1</sup>,</span>
            </span>

            <span class="author-block">
              <a href="https://liuhengyu321.github.io/">Hengyu Liu</a><sup>2</sup>,</span>
            </span>
            <span class="author-block">
              <a href="https://dblp.org/pid/251/4038.html">Haote Xu</a><sup>1</sup>,</span>
            </span>

            <br>
            <span class="author-block">
              <a href="https://yifliu3.github.io/">Yifan Liu</a><sup>2</sup>,
            </span>
            
            <span class="author-block">
              <a href="https://huangyue05.github.io/">Yue Huang</a><sup>1‡</sup>,</span>
            </span>

            <span class="author-block">
              <a href="https://xmu-smartdsp.github.io/teamindex/xhding.html">Xinghao Ding</a><sup>1,3</sup>,</span>
            </span>

            <span class="author-block">
              <a href="http://www.ee.cuhk.edu.hk/~yxyuan/people/people.htm">Yixuan Yuan</a><sup>2</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>School of Informatics, Xiamen University,</span>
            <span class="author-block"><sup>2</sup>The Chinese University of Hong,</span> <br>
            <span class="author-block"><sup>3</sup>Key Laboratory of Multimedia Trusted Perception and Efficient Computing, Xiamen University</span>
          </div>

          <div class="is-size-6 publication-authors">
            † denotes equal contribution, ‡ denotes corresponding author
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>

              <span class="link-block">
                <a href="#bib"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file"></i>
                  </span>
                  <span>BibTeX</span>
                </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <hr style="margin-top:0px">
        <div class="content has-text-justified">
          <p>
          The ability to generate an array of plausible outputs for a single input has profound implications for dealing with inherent ambiguity in visual scenarios. 
          This is evident in scenarios where diverse semantic segmentation annotations for a single medical image are provided by various experts.
          Existing methods hinge on probabilistic modelling of representations to depict this ambiguity and rely on extensive multi-output annotated data to learn this probabilistic space. 
          </p>
          <p>
            However, these methods often falter when only a limited amount of ambiguously labelled data is available, which is a common occurrence in real-world applications. 
            To surmount these challenges, we propose a novel framework, termed as <span class="gradient-text">P&sup2;SAM</span>, that leverages the prior knowledge of the Segment Anything Model (SAM) during the segmentation of ambiguous objects. 
            Specifically, we delve into an inherent drawback of SAM in deterministic segmentation, i.e., the sensitivity of output to prompts, and ingeniously transform this into an advantage for ambiguous segmentation tasks by introducing a prior probabilistic space for prompts. 
          </p>
          <p>
            Experimental results demonstrate that our strategy significantly enhances the precision and diversity of medical segmentation through the utilization of a small number of ambiguously annotated samples by doctors. 
            Rigorous benchmarking experiments against state-of-the-art methods indicate that our method achieves superior segmentation precision and diversified outputs with fewer training data (using simply 5.5% samples, +12% D<sub>max</sub>). 
          </p>
          <p>
            The <span class="gradient-text">P&sup2;SAM</span> signifies a substantial step towards the practical deployment of probabilistic models in real-world scenarios with limited data.
          </p>
          
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Pipeline</h2>
        <hr style="margin-top:0px">
        <img src="./static/images/method.jpg" alt="" width="800" height="400" class="center">
        

        <div class="content has-text-justified">
          <p>
            <strong>Overview of <span class="gradient-text">P&sup2;SAM</span>:</strong>
            (a) We first lift the conventional SAM prompting to the probabilistic space, by leveraging a network targeting at generating prompt distribution. 
            (b) Then we sample the prompt embedding from the probabilistic latent space and instill it into SAM to unlock the capacity of SAM in "one-to-many" ambiguous segmentation. 
            (c) We carefully design a diversity-aware assembling that perceives the inherent diversity in SAM and turn it to ensembled ambiguous output.
          </p>
        </div>

    
    <div class="container is-max-desktop">

      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Experiments</h2>
          <hr style="margin-top:0px">
          <h2 class="title is-4">Results on LIDC-IDRI</h2>
          <img src="./static/images/res_LIDC_1.jpg" alt="" width="1000" height="400" class="center">
          <img src="./static/images/res_LIDC_2.png" alt="" width="800" height="300" class="center">
          <img src="./static/images/res_LIDC_3.png" alt="" width="800" height="300" class="center">
          <hr style="margin-top:0px">

          <h2 class="title is-4">Results on BraTS2017</h2>
          <img src="./static/images/res_BraTS2017_1.jpg" alt="" width="1000" height="250" class="center"> 
          <img src="./static/images/res_BraTS2017_2.png" alt="" width="800" height="250" class="center"> 

        </div>
      </div>
    </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title" id="bib">BibTeX</h2>
    <hr style="margin-top:0px">
    <pre><code>
@article{huang2024p2sam,
  title={P²SAM: Probabilistically Prompted SAMs Are Efficient Segmentator for Ambiguous Medical Images},
  author={Huang, Yuzhi and Li, Chenxin and Lin, Zixu and Liu, Hengyu and Xu Haote and Liu, Yifan and Huang, Yue and Ding, Xinghao and Yuan, Yixuan},
  journal={arXiv preprint arXiv:2407.01301},
  year={2024}
}
    </code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            The template is borrowed from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
